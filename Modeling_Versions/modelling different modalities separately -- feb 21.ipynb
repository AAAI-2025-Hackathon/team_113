{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a7813cc",
   "metadata": {},
   "source": [
    "# not changed for before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d76a7d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbeec69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling_batch(matrices, new_shape):\n",
    "    original_batch, original_height, original_width = matrices.shape  \n",
    "    target_height, target_width = new_shape\n",
    "    pool_size = original_width // target_width\n",
    "    reshaped = matrices.reshape(original_batch, original_height, target_width, pool_size)\n",
    "    pooled = np.max(reshaped, axis=3)\n",
    "    return pooled\n",
    "\n",
    "def count_and_percentage(array):\n",
    "    flattened = array.flatten()\n",
    "    unique, counts = np.unique(flattened, return_counts=True)\n",
    "    total_elements = flattened.size\n",
    "    count_dict = dict(zip(unique, counts))\n",
    "    percentage_dict = {key: (value / total_elements) * 100 for key, value in count_dict.items()}\n",
    "    return count_dict, percentage_dict\n",
    "\n",
    "def resize_tensor_bilinear(tensor, target_size, mode='bilinear'):\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    resized = F.interpolate(tensor, size=target_size, mode=mode, align_corners=False)\n",
    "    return resized.squeeze(0)\n",
    "\n",
    "def resize_tensor_nearest(tensor, target_size, mode='nearest'):\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    resized = F.interpolate(tensor, size=target_size, mode=mode)\n",
    "    return resized.squeeze(0)\n",
    "\n",
    "\n",
    "def normalize_tensor(tensor):\n",
    "    min_val = tensor.min(dim=-1, keepdim=True).values.min(dim=-2, keepdim=True).values\n",
    "    max_val = tensor.max(dim=-1, keepdim=True).values.max(dim=-2, keepdim=True).values\n",
    "    return ((tensor - min_val) / ((max_val - min_val) + 1e-8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c6c7c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anylithicdpt_2D_matrix.npy\n",
      "resdept_2D_matrix.npy\n"
     ]
    }
   ],
   "source": [
    "#ELEVATION DATA\n",
    "elevation_data = np.load('elevation_matrix.npy') \n",
    "\n",
    "#VEGETATION DATA\n",
    "vegetation_data = np.load('NLCD2021_OR.npy') \n",
    "\n",
    "#SOIL VARIABLE DATA\n",
    "directory = \"ERA5_matrices\"  \n",
    "npy_files = sorted([f for f in os.listdir(directory) if f.endswith('.npy')])\n",
    "matrices = [np.load(os.path.join(directory, file)) for file in npy_files]\n",
    "data = np.stack(matrices, axis=0)  # Shape: (num_files, height, width)\n",
    "soil_variable_data = np.transpose(data, (1, 0, 2, 3)) \n",
    "\n",
    "#SOIL COMPOSITION DATA\n",
    "data_folder = \"SOLUS\"\n",
    "npy_files = [f for f in os.listdir(data_folder) if f.endswith('.npy')]\n",
    "num_files = len(npy_files)\n",
    "transformed_data_list = []\n",
    "pca = PCA(n_components=1)\n",
    "for file in npy_files:\n",
    "    file_path = os.path.join(data_folder, file)\n",
    "    soil_data = np.load(file_path)\n",
    "    try:\n",
    "        reshaped_data = soil_data.reshape(7, -1).T\n",
    "    except:\n",
    "        print(file)\n",
    "        continue\n",
    "    principal_component = pca.fit_transform(reshaped_data)  \n",
    "    reduced_data = principal_component.reshape(1306, 464)\n",
    "    transformed_data_list.append(reduced_data)\n",
    "soil_composition_data = np.stack(transformed_data_list, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fdd019f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELEVATION DATA : (10812, 10812)\n",
      "VEGETATION DATA : (15, 4353, 1547)\n",
      "SOIL VARIABLE DATA : (1096, 28, 5, 5)\n",
      "SOIL COMPOSITION DATA : (18, 1306, 464)\n"
     ]
    }
   ],
   "source": [
    "print(f\"ELEVATION DATA : {elevation_data.shape}\")\n",
    "print(f\"VEGETATION DATA : {vegetation_data.shape}\")\n",
    "print(f\"SOIL VARIABLE DATA : {soil_variable_data.shape}\")\n",
    "print(f\"SOIL COMPOSITION DATA : {soil_composition_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f54b1739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts: {0.0: 15118676, 1.0: 303439, 2.0: 360285}\n",
      "Percentages: {0.0: 95.79453061638281, 1.0: 1.9226416768045418, 2.0: 2.282827706812652}\n"
     ]
    }
   ],
   "source": [
    "label = np.load('landslide_labels_stored_sequentially_compressed.npz') \n",
    "output_labels = label['matrix']\n",
    "labels_resized = max_pooling_batch(output_labels, (120, 120))  # Output shape: (1096, 120, 120)\n",
    "counts, percentages = count_and_percentage(labels_resized)\n",
    "print(\"Counts:\", counts)  \n",
    "print(\"Percentages:\", percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "804cc8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT LABELS : (1096, 120, 120)\n"
     ]
    }
   ],
   "source": [
    "print(f\"OUTPUT LABELS : {labels_resized.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ccd4abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 120])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_mask = np.load('spatial_mask.npy') \n",
    "spatial_mask = torch.tensor(spatial_mask, dtype=torch.float)\n",
    "spatial_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0054b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation_data = torch.tensor(elevation_data, dtype=torch.float).unsqueeze(0)  # (1, 10812, 10812)\n",
    "vegetation_data = torch.tensor(vegetation_data, dtype=torch.float)             # (15, 4353, 1547)\n",
    "soil_composition_data = torch.tensor(soil_composition_data, dtype=torch.float) # (18, 1306, 464)\n",
    "soil_variable_data = torch.tensor(soil_variable_data, dtype=torch.float)       # (1096, 28, 5, 5)\n",
    "output_labels = torch.tensor(labels_resized, dtype=torch.long)                 # (1096, 120, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "061a3bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELEVATION DATA : torch.Size([1, 10812, 10812])\n",
      "VEGETATION DATA : torch.Size([15, 4353, 1547])\n",
      "SOIL VARIABLE DATA : torch.Size([1096, 28, 5, 5])\n",
      "SOIL COMPOSITION DATA : torch.Size([18, 1306, 464])\n",
      "OUTPUT LABELS : torch.Size([1096, 120, 120])\n"
     ]
    }
   ],
   "source": [
    "print(f\"ELEVATION DATA : {elevation_data.shape}\")\n",
    "print(f\"VEGETATION DATA : {vegetation_data.shape}\")\n",
    "print(f\"SOIL VARIABLE DATA : {soil_variable_data.shape}\")\n",
    "print(f\"SOIL COMPOSITION DATA : {soil_composition_data.shape}\")\n",
    "print(f\"OUTPUT LABELS : {output_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71c96a7",
   "metadata": {},
   "source": [
    "# my changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfa7b648",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DayDataset(Dataset):\n",
    "    def __init__(self, day_indices, vegetation, elevation, soil_comp, soil_var, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          day_indices: list of day indices (e.g., [0, 1, 2, ...])\n",
    "          vegetation: static vegetation data, already resized, shape (15, target_H, target_W)\n",
    "          elevation: static elevation data, already resized, shape (1, target_H, target_W)\n",
    "          soil_comp: static soil composition data, already resized, shape (18, target_H, target_W)\n",
    "          soil_var: daily soil variable data, shape (1096, 28, 5, 5)\n",
    "          labels: daily output labels, shape (1096, target_H, target_W)\n",
    "          target_size: the target spatial size (target_H, target_W) for all inputs\n",
    "        \"\"\"\n",
    "        self.day_indices = day_indices\n",
    "        self.vegetation = vegetation\n",
    "        self.elevation = elevation\n",
    "        self.soil_comp = soil_comp\n",
    "        self.soil_var = soil_var\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.day_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        day = self.day_indices[idx]\n",
    "        soil_var_day = self.soil_var[day] \n",
    "        #input_tensor = torch.cat([self.vegetation, self.elevation, self.soil_comp, soil_variable_normalized], dim=0)\n",
    "        label = self.labels[day]\n",
    "        \n",
    "        return self.vegetation, self.elevation, self.soil_comp, soil_var_day, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae078f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_days = list(range(1096))\n",
    "# train_days = list(range(0, 730))\n",
    "# test_days = list(range(730, 1096))\n",
    "# val_days = train_days[-100:] \n",
    "# train_days = train_days[:-100]\n",
    "all_days = list(range(1096))\n",
    "train_days = list(range(0, 730))\n",
    "test_days = list(range(730, 1096))\n",
    "val_days = random.sample(train_days, 100) # Randomly select 100 days from train_days for validation\n",
    "train_days = [day for day in train_days if day not in val_days] # Remove the selected validation days from train_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91f8dfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DayDataset(train_days, vegetation_data, elevation_data,\n",
    "                           soil_composition_data, soil_variable_data, output_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abf812da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1cc356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = DayDataset(val_days, vegetation_data, elevation_data,\n",
    "                           soil_composition_data, soil_variable_data, output_labels)\n",
    "test_dataset = DayDataset(test_days, vegetation_data, elevation_data,\n",
    "                           soil_composition_data, soil_variable_data, output_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f6ae3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76bcc0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MutliModalFCN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94d9d1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "model = FCN(4, num_classes)\n",
    "model_veg = VegetationConvNet()\n",
    "model_elevation = ElevationConvNet()\n",
    "model_ERA = ERA5ConvNet()\n",
    "model_solus = SOLUSConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6f2d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model_veg.to(device)\n",
    "model_elevation.to(device)\n",
    "model_ERA.to(device)\n",
    "model_solus.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bf64d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict()\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict()\n",
    "            self.counter = 0\n",
    "\n",
    "    def load_best_model(self, model):\n",
    "        model.load_state_dict(self.best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56b1b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MaskedCrossEntropyLoss(torch.nn.Module):\n",
    "    def __init__(self, class_weights=None):\n",
    "        super(MaskedCrossEntropyLoss, self).__init__()\n",
    "        # If class weights are provided, store them as a tensor\n",
    "        if class_weights is not None:\n",
    "            self.class_weights = torch.tensor(class_weights).float()\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "            \n",
    "            \n",
    "    def forward(self, outputs, labels, spatial_mask):\n",
    "        # Flatten the outputs, labels, and spatial_mask\n",
    "        B, C, H, W = outputs.shape\n",
    "        outputs_flat = outputs.view(B, C, -1)  # shape: (B, C, H*W)\n",
    "        labels_flat = labels.view(B, -1)  # shape: (B, H*W)\n",
    "        \n",
    "        # Expand the spatial mask to match the shape of outputs (B, H, W)\n",
    "        spatial_mask_expanded = spatial_mask.unsqueeze(0).expand(B, -1, -1)  # shape: (B, H, W)\n",
    "        spatial_mask_flat = spatial_mask_expanded.view(B, -1)  # shape: (B, H*W)\n",
    "\n",
    "        # Apply the spatial mask (only consider masked positions)\n",
    "        mask_indices = spatial_mask_flat == 1\n",
    "\n",
    "        # Flatten the outputs and labels to (B*H*W, C) and (B*H*W,)\n",
    "        outputs_flat = outputs_flat.view(-1, C)  # shape: (B*H*W, C)\n",
    "        labels_flat = labels_flat.view(-1)  # shape: (B*H*W,)\n",
    "        \n",
    "        # Apply mask to the flattened outputs and labels\n",
    "        masked_outputs = outputs_flat[mask_indices.view(-1)]\n",
    "        masked_labels = labels_flat[mask_indices.view(-1)]\n",
    "\n",
    "        # Calculate the cross-entropy loss only on masked positions\n",
    "        if masked_outputs.size(0) > 0:  # Avoid division by zero\n",
    "            loss = F.cross_entropy(masked_outputs, masked_labels, weight=self.class_weights)\n",
    "        else:\n",
    "            loss = torch.tensor(0.0).to(outputs.device)\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c4ba1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1530028/753182092.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.class_weights = torch.tensor(class_weights).float()\n"
     ]
    }
   ],
   "source": [
    "freq = torch.tensor([0.923, 0.038, 0.039])\n",
    "weights = 1.0 / freq\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "criterion = MaskedCrossEntropyLoss(class_weights = weights)  \n",
    "optimizer = optim.AdamW(list(model.parameters())+list(model_veg.parameters())+list(model_elevation.parameters())+\n",
    "                        list(model_ERA.parameters())+list(model_solus.parameters()), lr=0.01, weight_decay=0.0001)\n",
    "early_stopping = EarlyStopping(patience=15, delta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8ebb430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000  Train Loss: 1.1071  Val Loss: 1.0202\n",
      "Epoch 2/1000  Train Loss: 0.9545  Val Loss: 0.9225\n",
      "Epoch 3/1000  Train Loss: 0.9098  Val Loss: 0.9076\n",
      "Epoch 4/1000  Train Loss: 0.8893  Val Loss: 0.8900\n",
      "Epoch 5/1000  Train Loss: 0.8834  Val Loss: 0.8746\n",
      "Epoch 6/1000  Train Loss: 0.8696  Val Loss: 0.9024\n",
      "Epoch 7/1000  Train Loss: 0.8635  Val Loss: 0.8774\n",
      "Epoch 8/1000  Train Loss: 0.8575  Val Loss: 0.8708\n",
      "Epoch 9/1000  Train Loss: 0.8514  Val Loss: 0.8870\n",
      "Epoch 10/1000  Train Loss: 0.8486  Val Loss: 0.8665\n",
      "Epoch 11/1000  Train Loss: 0.8491  Val Loss: 0.8812\n",
      "Epoch 12/1000  Train Loss: 0.8512  Val Loss: 0.8724\n",
      "Epoch 13/1000  Train Loss: 0.8479  Val Loss: 0.8543\n",
      "Epoch 14/1000  Train Loss: 0.8439  Val Loss: 0.8549\n",
      "Epoch 15/1000  Train Loss: 0.8442  Val Loss: 0.8649\n",
      "Epoch 16/1000  Train Loss: 0.8461  Val Loss: 0.8614\n",
      "Epoch 17/1000  Train Loss: 0.8448  Val Loss: 0.8583\n",
      "Epoch 18/1000  Train Loss: 0.8419  Val Loss: 0.8592\n",
      "Epoch 19/1000  Train Loss: 0.8418  Val Loss: 0.8519\n",
      "Epoch 20/1000  Train Loss: 0.8419  Val Loss: 0.8522\n",
      "Epoch 21/1000  Train Loss: 0.8385  Val Loss: 0.8505\n",
      "Epoch 22/1000  Train Loss: 0.8395  Val Loss: 0.8557\n",
      "Epoch 23/1000  Train Loss: 0.8413  Val Loss: 0.8525\n",
      "Epoch 24/1000  Train Loss: 0.8391  Val Loss: 0.8507\n",
      "Epoch 25/1000  Train Loss: 0.8385  Val Loss: 0.8452\n",
      "Epoch 26/1000  Train Loss: 0.8453  Val Loss: 0.8449\n",
      "Epoch 27/1000  Train Loss: 0.8362  Val Loss: 0.8535\n",
      "Epoch 28/1000  Train Loss: 0.8384  Val Loss: 0.8421\n",
      "Epoch 29/1000  Train Loss: 0.8355  Val Loss: 0.8512\n",
      "Epoch 30/1000  Train Loss: 0.8367  Val Loss: 0.8511\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1530028/3961184683.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mveg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_veg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0melevation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_elevation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mera\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_ERA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0msolus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_solus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/AAAI hackathon/MutliModalFCN.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# Apply convolutions and pooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# Flatten the output of the convolutional layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    451\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 453\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    454\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "num_epochs = 1000\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 15 # Number of epochs to wait for improvement\n",
    "best_val_loss = float('inf')  # Initialize best validation loss as a large number\n",
    "patience_counter = 0.0 # Counter for epochs with no improvement\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs in train_loader:\n",
    "        labels = inputs[-1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        veg = model_veg(inputs[0].to(device))\n",
    "        elevation = model_elevation(inputs[1].squeeze(1).to(device))\n",
    "        era = model_ERA(inputs[3].to(device))\n",
    "        solus = model_solus(inputs[2].to(device))\n",
    "        \n",
    "        outputs = model(torch.stack((veg, elevation, era, solus), dim=1))      # shape: (B, 3, 120, 120)\n",
    "        loss = criterion(outputs, labels, spatial_mask)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs[0].size(0)\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    train_losses.append(epoch_loss)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs in val_loader:\n",
    "            labels = inputs[-1].to(device)\n",
    "            \n",
    "            veg = model_veg(inputs[0].to(device))\n",
    "            elevation = model_elevation(inputs[1].squeeze(1).to(device))\n",
    "            era = model_ERA(inputs[3].to(device))\n",
    "            solus = model_solus(inputs[2].to(device))\n",
    "            \n",
    "            outputs = model(torch.stack((veg, elevation, era, solus), dim=1))\n",
    "            loss = criterion(outputs, labels, spatial_mask)\n",
    "            val_loss += loss.item() * inputs[0].size(0)\n",
    "    epoch_val_loss = val_loss / len(val_dataset)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}  Train Loss: {epoch_loss:.4f}  Val Loss: {epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        patience_counter = 0  # Reset counter if we have improvement\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1} due to no improvement in validation loss.\")\n",
    "            break\n",
    "\n",
    "epochs_run = epoch + 1\n",
    "\n",
    "end = time.time()\n",
    "duration = (end-start)/60\n",
    "print(f\"The training loop ran for {round(duration,2)} minutes for {epochs_run} epochs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49c29ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAGDCAYAAABuj7cYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAAsTAAALEwEAmpwYAABVQ0lEQVR4nO3deXxU5b3H8c8vewhJCBASIKxWAsgO7lVBrbsgilarrWjr1qqtvW3tcluty1V7vV3o5tJa933BXdzFilpA2TcBQRL2QDayzzz3j3MSAiQhy0xmknzfr9e8ZuacM2d+M4zw9XnO8zzmnENEREREokNMpAsQERERkb0UzkRERESiiMKZiIiISBRROBMRERGJIgpnIiIiIlFE4UxEREQkiiiciUizmNnrZnZpqI/tyMxsspnl1Xu+3MwmN+fYVrzXPWb269a+XkQ6jrhIFyAi4WNmpfWedgMqgYD//Crn3GPNPZdz7vRwHBtJZpYEbAXOdc69u9++PwADnHMzmns+59xhIaprJvA959zX65376lCcu4H3uhn4mnPuknCcX0RaTi1nIp2Yc6577Q34Cji73ra6YGZmXfJ/1JxzFcBTwHfqbzezWOAi4KFI1CUiXZvCmUgXVNvFZmY3mtlW4F9mlmFmr5jZDjPb7T/Oqfea983se/7jmWb2bzO72z/2SzM7vZXHDjGzuWZWYmZvm9lfzezRRupeaWZn1Xse59c7wcySzOxRMysws0Izm29mWc34Oh4CzjOzbvW2nYr39+PrZnaZ/74lZrbezK5q4nvdYGYn+4+TzexB/zOvAA7f79ifm9k6/7wrzGy6v30EcA9wtJmVmlmhv/1BM7ut3uuvMLO1ZrbLzF4ys3719jkzu9rMvvC/i7+amTXju9j/80z1u2oL/T/TEfX23Whm+X79q83sJH/7EWa2wMyKzWybmf2+pe8r0tUpnIl0XdlAT2AQcCXe3wf/8p8PBMqBvzTx+iOB1UBv4HfAP5sIAE0d+zjwH6AXcDPw7Sbe8wm8Fq1apwI7nXOfAZcC6cAA/1xX+5+hSc65ecAW4Nx6m78NPO6cqwG2A2cBacBlwB/MbMLBzgvcBBzi307166tvHXCcX/NvgUfNrK9zbqVf+8d+C2eP/U9sZicCdwAXAH2BjcCT+x12Fl4gHOMfd2ozaq7/HsPwvu8fAZnAa8DLZpZgZrnAtcDhzrlU/9wb/Jf+CfiTcy7N/+xPt+R9RUThTKQrCwI3OecqnXPlzrkC59xzzrky51wJcDtwQhOv3+icu985F8BrfeoLNNZS1eCxZjYQL0D8xjlX5Zz7N/BSE+/5ODC1XivXt/ACBEA1Xij7mnMu4Jxb6JwrPui34HkYv2vTzNKAaX6dOOdedc6tc54PgDfxQtXBXADc7pzb5ZzbBMyqv9M594xzbrNzLuicewr4AjiimfVeDDzgnPvMOVcJ/AKvpW1wvWPudM4VOue+At4DxjXz3LW+CbzqnHvLOVcN3A0kA8fgXbeYCIw0s3jn3Abn3Dr/ddXA18yst3Ou1Dn3SQvfV6TLUzgT6bp2+NdcAWBm3czsXjPbaGbFwFygh3/9VUO21j5wzpX5D7u38Nh+wK562wA2NVawc24tsBI42w9oU/ECG8AjwBzgSTPbbGa/M7P4xs61n0eAKX7X4AxgnXPucwAzO93MPvG7DwuBM/BaAA+m336fZWP9nWb2HTNb5HcZFgKjmnne2nPXnc85VwoUAP3rHbO13uMyGv+zae57BPE+T3//z+FHeC2d283syXrdqt8FhgGr/K7lsxCRFlE4E+m63H7P/wvIBY70u6SO97e3+FqlFtgC9Nzveq8BB3lNbdfmNGCFHxRwzlU7537rnBuJ17pzFvtd6N8Y59xG4EPgErwuzYcAzCwReA6v1SjL72J8jeZ9J1v2+ywDax+Y2SDgfryuwV7+eZfVO+/+fzb724zX/Vx7vhS8VsP8ZtTVXPu/h+F9nnwA59zj/mjSQX69d/nbv3DOXQT08bc969cnIs2kcCYitVLxrtEqNLOeeNdMhZUfihYAN/vXMh0NnH2Qlz0JnAJcw95WM8xsipmN9lv6ivG614ItKOchvLB0LFA7kjUBr/tuB1DjD2Q4pZnnexr4hXkDLXKA6+rtS8ELNDv82i/DazmrtQ3IMbOERs79BHCZmY3zA+T/AJ865zY0s7b9xfgDKmpviX79Z5rZSX4L5H/hTcUyz8xyzexE/7gKvN9N0P8sl5hZpt/SVuifvyV/DiJdnsKZiNT6I941RTuBT4A32ul9LwaOxuuWuw1vaovKxg52zm0BPsZrHXuq3q5s4Fm8YLYS+ACvu7J2Atd7DlLHc3gDJN7x3wP/2rvr8YLKbrxr3Jq6Jq6+3+J1C36Jd53aI/U+wwrg//zPsQ0YDXxU77XvAsuBrWa2c/8TO+feBn7t17wF78L7C5tZV0MuwgtYtbd1zrnVeC2Jf8b7TZyNNxVLFV5gvdPfvhWvlewX/rlOA5abN8fen4ALnXMHHZghInuZcwdrPRcRaT9m9hSwyjkX9pY7EZFopJYzEYkoMzvczA4xsxgzOw3vWrLZES5LRCRiuuSs4CISVbKB5/EuaM8DrqkdKSki0hWpW1NEREQkiqhbU0RERCSKKJyJiIiIRJFOc81Z79693eDBgyNdhoiIiMhBLVy4cKdzLrOhfZ0mnA0ePJgFCxZEugwRERGRgzKzjY3tU7emiIiISBRROBMRERGJIgpnIiIiIlGk01xzJiIi0tlVV1eTl5dHRUVFpEuRZkpKSiInJ4f4+Phmv0bhTEREpIPIy8sjNTWVwYMHY2aRLkcOwjlHQUEBeXl5DBkypNmvU7emiIhIB1FRUUGvXr0UzDoIM6NXr14tbulUOBMREelAFMw6ltb8eSmciYiISLMUFBQwbtw4xo0bR3Z2Nv379697XlVV1eRrFyxYwPXXX3/Q9zjmmGNCUuv777/PWWedFZJztTddcyYiIiLN0qtXLxYtWgTAzTffTPfu3fnJT35St7+mpoa4uIajxaRJk5g0adJB32PevHkhqbUjU8uZiIiItNrMmTO5+uqrOfLII/nZz37Gf/7zH44++mjGjx/PMcccw+rVq4F9W7JuvvlmLr/8ciZPnszQoUOZNWtW3fm6d+9ed/zkyZOZMWMGw4cP5+KLL8Y5B8Brr73G8OHDmThxItdff32LWsieeOIJRo8ezahRo7jxxhsBCAQCzJw5k1GjRjF69Gj+8Ic/ADBr1ixGjhzJmDFjuPDCC9v+ZTWTWs5EREQ6oN++vJwVm4tDes6R/dK46ezDWvy6vLw85s2bR2xsLMXFxXz44YfExcXx9ttv88tf/pLnnnvugNesWrWK9957j5KSEnJzc7nmmmsOmG7i888/Z/ny5fTr149jjz2Wjz76iEmTJnHVVVcxd+5chgwZwkUXXdTsOjdv3syNN97IwoULycjI4JRTTmH27NkMGDCA/Px8li1bBkBhYSEAd955J19++SWJiYl129qDWs6ayTnHR2t3smZbSaRLERERiSrnn38+sbGxABQVFXH++eczatQobrjhBpYvX97ga84880wSExPp3bs3ffr0Ydu2bQccc8QRR5CTk0NMTAzjxo1jw4YNrFq1iqFDh9ZNTdGScDZ//nwmT55MZmYmcXFxXHzxxcydO5ehQ4eyfv16rrvuOt544w3S0tIAGDNmDBdffDGPPvpoo9214aCWs2YyM65+ZCHnTczh5qkt/78KERGRUGpNC1e4pKSk1D3+9a9/zZQpU3jhhRfYsGEDkydPbvA1iYmJdY9jY2Opqalp1TGhkJGRweLFi5kzZw733HMPTz/9NA888ACvvvoqc+fO5eWXX+b2229n6dKl7RLS1HLWAlnpSWwt0qzMIiIijSkqKqJ///4APPjggyE/f25uLuvXr2fDhg0APPXUU81+7RFHHMEHH3zAzp07CQQCPPHEE5xwwgns3LmTYDDIeeedx2233cZnn31GMBhk06ZNTJkyhbvuuouioiJKS0tD/nkaopazFshOS2JrscKZiIhIY372s59x6aWXctttt3HmmWeG/PzJycn87W9/47TTTiMlJYXDDz+80WPfeecdcnJy6p4/88wz3HnnnUyZMgXnHGeeeSbTpk1j8eLFXHbZZQSDQQDuuOMOAoEAl1xyCUVFRTjnuP766+nRo0fIP09DrHbkQ0c3adIkt2DBgrC+x389vZh563by8S9OCuv7iIiINGTlypWMGDEi0mVEXGlpKd27d8c5xw9+8AMOPfRQbrjhhkiX1aiG/tzMbKFzrsG5RdSt2QJZaYlsL6kkEOwcgVZERKQjuv/++xk3bhyHHXYYRUVFXHXVVZEuKaTCFs7M7AEz225myxrZP9zMPjazSjP7yX77TjOz1Wa21sx+Hq4aWyo7PYlA0FGwpzLSpYiIiHRZN9xwA4sWLWLFihU89thjdOvWLdIlhVQ4W84eBE5rYv8u4Hrg7vobzSwW+CtwOjASuMjMRoapxhbJSksCYFuRwpmIiIiER9jCmXNuLl4Aa2z/dufcfKB6v11HAGudc+udc1XAk8C0cNXZEtl+ONOgABEREQmXaLzmrD+wqd7zPH/bAczsSjNbYGYLduzYEfbCstMVzkRERCS8ojGcNZtz7j7n3CTn3KTMzMywv1/v7onExhjbNNeZiIiIhEk0hrN8YEC95zn+toiLjTEyuyeq5UxERLqkKVOmMGfOnH22/fGPf+Saa65p9DWTJ0+mdqqrM844o8E1Km+++WbuvvvuA7bXN3v2bFasWFH3/De/+Q1vv/12C6pvWP0F2aNFNIaz+cChZjbEzBKAC4GXIlxTnaz0JLYpnImISBd00UUX8eSTT+6z7cknn2z2+pavvfZaqydy3T+c3XLLLZx88smtOle0C+dUGk8AHwO5ZpZnZt81s6vN7Gp/f7aZ5QE/Bv7bPybNOVcDXAvMAVYCTzvnGl41NQKyUhO1hJOIiHRJM2bM4NVXX6WqqgqADRs2sHnzZo477jiuueYaJk2axGGHHcZNN93U4OsHDx7Mzp07Abj99tsZNmwYX//611m9enXdMffffz+HH344Y8eO5bzzzqOsrIx58+bx0ksv8dOf/pRx48axbt06Zs6cybPPPgt4KwGMHz+e0aNHc/nll1NZWVn3fjfddBMTJkxg9OjRrFq1qtmf9YknnmD06NGMGjWKG2+8EYBAIMDMmTMZNWoUo0eP5g9/+AMAs2bNYuTIkYwZM4YLL7ywhd/qgcK2fJNzrskY7Zzbitdl2dC+14DXwlFXW2WnJ/HJ+oJIlyEiIl3d6z+HrUtDe87s0XD6nY3u7tmzJ0cccQSvv/4606ZN48knn+SCCy7AzLj99tvp2bMngUCAk046iSVLljBmzJgGz7Nw4UKefPJJFi1aRE1NDRMmTGDixIkAnHvuuVxxxRUA/Pd//zf//Oc/ue6665g6dSpnnXUWM2bM2OdcFRUVzJw5k3feeYdhw4bxne98h7///e/86Ec/AqB379589tln/O1vf+Puu+/mH//4x0G/hs2bN3PjjTeycOFCMjIyOOWUU5g9ezYDBgwgPz+fZcu8KVxru2jvvPNOvvzySxITExvstm2paOzWjGpZaUkUV9RQXhWIdCkiIiLtrn7XZv0uzaeffpoJEyYwfvx4li9fvk8X5P4+/PBDpk+fTrdu3UhLS2Pq1Kl1+5YtW8Zxxx3H6NGjeeyxx1i+vOnOs9WrVzNkyBCGDRsGwKWXXsrcuXPr9p977rkATJw4sW6x9IOZP38+kydPJjMzk7i4OC6++GLmzp3L0KFDWb9+Pddddx1vvPEGaWlpAIwZM4aLL76YRx99lLi4trd7aeHzFqo/19mQ3ikRrkZERLqsJlq4wmnatGnccMMNfPbZZ5SVlTFx4kS+/PJL7r77bubPn09GRgYzZ86koqJ1lwDNnDmT2bNnM3bsWB588EHef//9NtWbmJgIQGxsLDU1NW06V0ZGBosXL2bOnDncc889PP300zzwwAO8+uqrzJ07l5dffpnbb7+dpUuXtimkqeWshermOtN1ZyIi0gV1796dKVOmcPnll9e1mhUXF5OSkkJ6ejrbtm3j9ddfb/Icxx9/PLNnz6a8vJySkhJefvnlun0lJSX07duX6upqHnvssbrtqamplJSUHHCu3NxcNmzYwNq1awF45JFHOOGEE9r0GY844gg++OADdu7cSSAQ4IknnuCEE05g586dBINBzjvvPG677TY+++wzgsEgmzZtYsqUKdx1110UFRVRWlrapvdXy1kL1S3hpBGbIiLSRV100UVMnz69rntz7NixjB8/nuHDhzNgwACOPfbYJl8/YcIEvvnNbzJ27Fj69OnD4YcfXrfv1ltv5cgjjyQzM5MjjzyyLpBdeOGFXHHFFcyaNatuIABAUlIS//rXvzj//POpqanh8MMP5+qrr27R53nnnXfIydl7GfwzzzzDnXfeyZQpU3DOceaZZzJt2jQWL17MZZddRjAYBOCOO+4gEAhwySWXUFRUhHOO66+/vtUjUmuZc65NJ4gWkyZNcrXzqIRTaWUNo26aw89PH87VJxwS9vcTERGptXLlSkaMGBHpMqSFGvpzM7OFzrlJDR2vbs0W6p4YR/fEOHVrioiISFgonLVCn7REdWuKiIhIWCictUJ2mlYJEBERkfBQOGsFL5xVRroMERHpgjrLteJdRWv+vBTOWqF2fc1gUP+BiIhI+0lKSqKgoEABrYNwzlFQUEBSUlKLXqepNFohOy2JmqCjYE8VmamJkS5HRES6iJycHPLy8tixY0ekS5FmSkpK2meajuZQOGuF+nOdKZyJiEh7iY+PZ8iQIZEuQ8JM3ZqtoFUCREREJFwUzlqh/vqaIiIiIqGkcNYKvbsnEGNawklERERCT+GsFeJiY+jdXRPRioiISOgpnLVSdnoSWzXXmYiIiISYwlkrZaUlsU0DAkRERCTEFM5aKTstSQMCREREJOQUzlopOz2JovJqKqoDkS5FREREOhGFs1aqnYhWc52JiIhIKCmctZLmOhMREZFwUDhrpaw0b9kmTachIiIioaRw1kpZ6XvX1xQREREJFYWzVkpNjKNbQixbizTXmYiIiISOwlkrmRnZaUlqORMREZGQUjhrgyzNdSYiIiIhpnDWBtnpSZpKQ0REREJK4awNstKS2F5SQTDoIl2KiIiIdBIKZ22QnZZIdcCxq6wq0qWIiIhIJ6Fw1gZaJUBERERCTeGsDWrnOtteonAmIiIioaFw1gZ1SzhprjMREREJEYWzNshMTcRM62uKiIhI6CictUF8bAy9uyeyTdeciYiISIgonLVRtiaiFRERkRBSOGujLC3hJCIiIiGkcNZG2emJajkTERGRkFE4a6Os1CQKy6qpqA5EuhQRERHpBBTO2qh2rjN1bYqIiEgoKJy1Ue1cZ9uKNdeZiIiItJ3CWRtl+y1nuu5MREREQkHhrI1q19fUXGciIiISCgpnbZSWFEdyfKxazkRERCQkFM7ayMzITtdEtCIiIhIaYQtnZvaAmW03s2WN7Dczm2Vma81siZlNqLcvYGaL/NtL4aoxVLLStISTiIiIhEY4W84eBE5rYv/pwKH+7Urg7/X2lTvnxvm3qeErMTSytISTiIiIhEjYwplzbi6wq4lDpgEPO88nQA8z6xuuesIpOy2J7cWVOOciXYqIiIh0cJG85qw/sKne8zx/G0CSmS0ws0/M7Jx2r6yFstKSqAoE2V1WHelSREREpIOLi3QBjRjknMs3s6HAu2a21Dm3bv+DzOxKvC5RBg4c2N411qmb66yogp4pCRGrQ0RERDq+SLac5QMD6j3P8bfhnKu9Xw+8D4xv6ATOufucc5Occ5MyMzPDW20T6uY603VnIiIi0kaRDGcvAd/xR20eBRQ557aYWYaZJQKYWW/gWGBFBOs8KK0SICIiIqEStm5NM3sCmAz0NrM84CYgHsA5dw/wGnAGsBYoAy7zXzoCuNfMgnjh8U7nXFSHsz6piZh53ZoiIiIibRG2cOacu+gg+x3wgwa2zwNGh6uucIiPjaFXSqK6NUVERKTNtEJAiGSlJapbU0RERNpM4SxEstOS1K0pIiIibaZwFiJZ6UlsL6mMdBkiIiLSwSmchUh2WhK79lRRWROIdCkiIiLSgSmchUi2P9fZ9mK1nomIiEjrKZyFSJbmOhMREZEQUDgLkdqWMw0KEBERkbZQOAuRbC3hJCIiIiGgcBYiaclxJMbFqOVMRERE2kThLETMjOz0JF1zJiIiIm2icBZCWWlJGq0pIiIibaJwFkLZaWo5ExERkbZROAuh2m5Nb013ERERkZZTOAuhrLQkqmqCFJZVR7oUERER6aAUzkKobq4zdW2KiIhIKymchVB2eiKgcCYiIiKtp3AWQn1S/YloNdeZiIiItJLCWQhlqVtTRERE2kjhLIQS4mLolZLANs11JiIiIq2kcBZiWWlJWl9TREREWk3hLMSy05O0vqaIiIi0msJZiKnlTERERNpC4SzEstOSKNhTRWVNINKliIiISAekcBZitXOdaQF0ERERaQ2FsxDr40+noa5NERERaQ2FsxDTEk4iIiLSFgpnzRUMwrLnYdP8Jg/Lrms5U7emiIiItJzCWXOZwas/hkWPNXlYj27xJMTFqFtTREREWkXhrLnMIHM47Fh9kMOM7DTNdSYiIiKto3DWEpm5sGMlONfkYdlpSbrmTERERFpF4awlModD+W7Ys7PJw7LSNRGtiIiItI7CWUtk5nr3O1Y1eVh2WiJbiypwB2lhExEREdmfwllLZA737g8SzrLSkqisCVJUXt0ORYmIiEhnonDWEql9ITHtoIMCsjTXmYiIiLSSwllLmPmDAg7SrZmuuc5ERESkdRTOWioz96AtZ3UT0Wo6DREREWkhhbOWyhwOe7ZD2a5GD+mT5i1+rm5NERERaSmFs5aqGxTQeOtZYlwsPVMSFM5ERESkxRTOWqqZ02lkpSWpW1NERERaTOGspdJyID6lGdedJarlTERERFpM4aylYmIgc1jzWs4UzkRERKSFFM5aoxkLoGelJbGztIqqmmA7FSUiIiKdgcJZa2TmQslmqChq9JDauc52lGquMxEREWk+hbPWqBuxuabRQ2rnOtuqQQEiIiLSAgpnrdGMEZu1SzjpujMRERFpCYWz1ugxCOKSmgxntd2aajkTERGRlghbODOzB8xsu5kta2S/mdksM1trZkvMbEK9fZea2Rf+7dJw1dhqMbHQ+9AmBwVkdIsnIS5GLWciIiLSIuFsOXsQOK2J/acDh/q3K4G/A5hZT+Am4EjgCOAmM8sIY52tc5ARm2ZGluY6ExERkRYKWzhzzs0FGl+AEqYBDzvPJ0APM+sLnAq85Zzb5ZzbDbxF0yEvMjJzoegrqCxt9JCs1CR1a4qIiEiLRPKas/7ApnrP8/xtjW0/gJldaWYLzGzBjh07wlZog2pHbO5sfMRmVromohUREZGW6dADApxz9znnJjnnJmVmZrbvmzdjAfTstCS2FlfgnGunokRERKSji2Q4ywcG1Hue429rbHt0yRgCMfFNj9hMS6KiOkhxRU07FiYiIiIdWSTD2UvAd/xRm0cBRc65LcAc4BQzy/AHApzib4susXEHHbGZla65zkRERKRl4sJ1YjN7ApgM9DazPLwRmPEAzrl7gNeAM4C1QBlwmb9vl5ndCsz3T3WLc66pgQWRk5kLmxc1urv+KgHDslLbqSgRERHpyMIWzpxzFx1kvwN+0Mi+B4AHwlFXSGUOh+Wzoboc4pMP2F0XztRyJiIiIs3UoQcERFxmLuBg5xcN7u6TlgjANk2nISIiIs2kcNYWBxmxmRQfS49u8Wo5ExERkWZTOGuLnoeAxR50xKYGBIiIiEhzKZy1RVwC9DqkyXCW5c91JiIiItIcCmdtlZl70IlotxVXtmNBIiIi0pEpnLVV5nDYtR5qGg5gWelJ7CytpDoQbOfCREREpCNSOGurzOHgAlCwrsHd2WlJOAc7StR6JiIiIgencNZWmbnefSPXnWWne9Np6LozERERaQ6Fs7bq9TWwmEavO8vyJ6LVXGciIiLSHApnbRWfDBmDG205y9IqASIiItICCmehkDm80Zaznt0SiI81hTMRERFpFoWzUMjMhYK1EKg+YFdMjNEnNUndmiIiItIsCmehkDkcgtWw68sGd2ena64zERERaR6Fs1A42IhNLeEkIiIizaRwFgq9h3n3TYzY3FpcgXOuHYsSERGRjkjhLBQSUqDHwCbnOiurClBSWdPOhYmIiEhHo3AWKk2M2NRcZyIiItJczQpnZpZiZjH+42FmNtXM4sNbWgeTmQs710AwcMAuzXUmIiIizdXclrO5QJKZ9QfeBL4NPBiuojqkzOEQqITdGw7YlV0bztRyJiIiIgfR3HBmzrky4Fzgb86584HDwldWB9S7dsTmgV2b2el+t6ZazkREROQgmh3OzOxo4GLgVX9bbHhK6qAya0dsHjgoICk+lvTkeM11JiIiIgfV3HD2I+AXwAvOueVmNhR4L2xVdURJ6ZDar9FBAdn+dBoiIiIiTYlrzkHOuQ+ADwD8gQE7nXPXh7OwDikzF3Y2MmIzXRPRioiIyME1d7Tm42aWZmYpwDJghZn9NLyldUCZw2HHGggGD9iVnZaoAQEiIiJyUM3t1hzpnCsGzgFeB4bgjdiU+jJzoXoPFOcdsCsrLYmdpZXUBA4MbiIiIiK1mhvO4v15zc4BXnLOVQNai2h/mcO9+wauO8tKSyLoYEepBgWIiIhI45obzu4FNgApwFwzGwQUh6uoDquJBdA115mIiIg0R3MHBMwCZtXbtNHMpoSnpA6sW09I6dNwONNcZyIiItIMzR0QkG5mvzezBf7t//Ba0WR/mbmNdmsCmutMREREmtTcbs0HgBLgAv9WDPwrXEV1aLULoLt9L8nrlZJAfKxprjMRERFpUrO6NYFDnHPn1Xv+WzNbFIZ6Or7MXKgshpItkNavbnNMjNEnNYltuuZMREREmtDclrNyM/t67RMzOxYoD09JHVzdiM0DrzvLSktUy5mIiIg0qbktZ1cDD5tZuv98N3BpeErq4OpPp3HIifvsykpLYvW2kggUJSIiIh1Fs1rOnHOLnXNjgTHAGOfceODEg7ysa0rpDck9G2k5U7emiIiINK253ZoAOOeK/ZUCAH4chno6PrO9gwL2k52exJ6qACUV1REoTERERDqCFoWz/VjIquhsMnNh+8oDRmxmp2muMxEREWlaW8KZlm9qTOZwqCiEPTv22ay5zkRERORgmhwQYGYlNBzCDEgOS0WdQf1lnLr3qdtcu0qAlnASERGRxjQZzpxzqe1VSKdSf8TmkOPrNtetr6luTREREWlEW7o1pTGp2ZCYfsCIzeSEWNKS4nTNmYiIiDRK4SwczJpcY1PdmiIiItIYhbNwycxtcK6z7PQktZyJiIhIoxTOwiVzuDdac0/BPpuz0pJ0zZmIiIg0SuEsXGoHBezct2szOy2JHSWV1ASCEShKREREop3CWbjUn06jnuF9Uwk6mL9hdwSKEhERkWincBYu6TmQ0P2AQQEnDc8iJSGWFxflR6gwERERiWZhDWdmdpqZrTaztWb28wb2DzKzd8xsiZm9b2Y59fYFzGyRf3spnHWGhRn0HtbgdBqnjsrm1aVbqKgORKg4ERERiVZhC2dmFgv8FTgdGAlcZGYj9zvsbuBh59wY4Bbgjnr7yp1z4/zb1HDVGVaNLIA+fXx/SipqeG/V9ggUJSIiItEsnC1nRwBrnXPrnXNVwJPAtP2OGQm86z9+r4H9HVtmLpRsgfLCfTYfc0hvMlMTma2uTREREdlPOMNZf2BTved5/rb6FgPn+o+nA6lm1st/nmRmC8zsEzM7p6E3MLMr/WMW7Nixo6FDIqtuxOaafTbHxhhTx/bjvVU7KCyrikBhIiIiEq0iPSDgJ8AJZvY5cAKQD9ReiDXIOTcJ+BbwRzM7ZP8XO+fuc85Ncs5NyszMbLeim62REZvgdW1WBYK8tnRrOxclIiIi0Syc4SwfGFDveY6/rY5zbrNz7lzn3HjgV/62Qv8+379fD7wPjA9jreHRYyDEJTd43dlh/dI4JDNFXZsiIiKyj3CGs/nAoWY2xMwSgAuBfUZdmllvM6ut4RfAA/72DDNLrD0GOBZYEcZawyMmFnof2mDLmZkxfXx//vPlLvJ2l0WgOBEREYlGYQtnzrka4FpgDrASeNo5t9zMbjGz2tGXk4HVZrYGyAJu97ePABaY2WK8gQJ3Ouc6XjiDRkdsAkwb512C99Lize1ZkYiIiESxuHCe3Dn3GvDaftt+U+/xs8CzDbxuHjA6nLW1m8xcWPo0VJZAYuo+uwb07MakQRm88Fk+15xwCGYWoSJFREQkWkR6QEDn18iIzVrnjO/PF9tLWbGluB2LEhERkWilcBZuteGska7NM0f3JS7GeHGRujZFRERE4Sz8MgZDbEKDgwIAMlISmJzbhxcX5RMIuvatTURERKKOwlm4xcZBr0MbbTkDb86zbcWVfLK+oB0LExERkWikcNYeMnMbbTkDOGlEH7onxjH7c815JiIi0tUpnLWHzOGweyNUNTyfWVJ8LKePyub1ZVupqA40eIyIiIh0DQpn7SEzF3BQ8EWjh0wf35/SyhreXrmt/eoSERGRqKNw1h4OMmIT4MihvchKS2T25xq1KSIi0pUpnLWHnkMhJq7J685iY4xp4/rz/urt7N5T1Y7FiYiISDRROGsPcQnQ85AmW84AzhnXn5qg49WlW9qpMBEREYk2Cmft5SAjNgFG9E1lWFZ3jdoUERHpwhTO2kvmcNi1HmoqGz3EzDhnfH8WbNzNpl0Nj+wUERGRzk3hrL1k5oILQsHaJg+bOrYfAC8uUuuZiIhIV6Rw1l7qRmw23bWZk9GNI4b05IXP83FOyzmJiIh0NQpn7aXX18BiDjooALw5z9bt2MOy/OJ2KExERESiicJZe4lPgowhB205AzhjVF8SYmOYra5NERGRLkfhrD1lDm9Wy1l6t3imDM/kpcWbqQkE26EwERERiRYKZ+0pM9cbEBCoPuih08f3Z0dJJfPWFbRDYSIiIhItFM7aU+ZwCNZ4U2ocxOTcPqQmxalrU0REpItROGtPmbnefTOuO0uKj+XM0X2Zs2wrZVU1YS5MREREooXCWXvqPQywZl13BnDO+P7sqQrw1opt4a1LREREoobCWXtK6AY9Bjar5QzgiME96ZeexIuLNoe5MBEREYkWCmftrZkjNgFiYoyp4/rzwZodFJQ2vuyTiIiIdB4KZ+0tMxd2roGyXc06fPr4/gSCjleXbglzYSIiIhINFM7a28hpgMG/Tofig3dX5manMjw7lRc+16hNERGRrkDhrL3lTIJLnoOiPHjg1GZNqzF9fH8+/6qQDTv3tEOBIiIiEkkKZ5Ew5Di49GWoLIUHToOty5o8fOq4fpihgQEiIiJdgMJZpPSfAJe/ARYLD54Bm/7T6KF905M5akgvZi/KxznXjkWKiIhIe1M4i6TMXC+gdesFD0+Dde82euj08f35cuceFucVtWOBIiIi0t4UziItYxBc9gb0HAqPXQArXmzwsNNGZ5MQF8NsDQwQERHp1BTOokFqFsx81evqfGYmfPbIAYekJcVz8og+vLx4M9WBYPvXKCIiIu1C4SxaJPeAb78AQ6fAS9fCvL8ccMg54/pTsKeKf6/d2f71iYiISLtQOIsmCSlw0ZMw8hx481fwzq1QbwDA5Nw+pCfH86K6NkVERDothbNoE5cAMx6ACd+BD++G134KQa8bMyEuhjPH9GXO8m3sqayJcKEiIiISDgpn0SgmFs6eBcdcD/PvhxeuhEA14I3aLK8O8OaKrREuUkRERMJB4SxamcEpt8JJN8HSZ+CpS6C6nIkDM+jfI5nZn2tCWhERkc5I4SzaHfdjOPP3sGYOPDqDmKoSzhnfjw+/2MGOkspIVyciIiIhpnDWERz+XTjvH7DpE3joLM7LTSLo4JmFmyJdmYiIiISYwllHMXoGXPgE7FjN0FfO57xDHH986wsWbSqMdGUiIiISQgpnHcmwU7y50Eq28ruSGxmfUsD3H11IQam6N0VERDoLhbOOZtAxMPMVYmvKeSThf4jds5XrnvicGq0aICIi0ikonHVEfcfCJc+TUFXMKxm/Z/m6jfzvm6sjXZWIiIiEgMJZR9VvHFz0OOllX/FSzz/z0AcreX3plkhXJSIiIm2kcNaRDTkezvsHA8uW8Uja3/j5MwtZu70k0lWJiIhIGyicdXQjp2Fn/Z7Dq+Zze+x9XP3wfEq1tJOIiEiHFdZwZmanmdlqM1trZj9vYP8gM3vHzJaY2ftmllNv36Vm9oV/uzScdXZ4ky6HKb/iLPcB3yz6Jz99ZjGu3oLpHcKXH8Ls70N1RaQrERERiaiwhTMziwX+CpwOjAQuMrOR+x12N/Cwc24McAtwh//ansBNwJHAEcBNZpYRrlo7heN/CodfwRWxrzBg5f3cO3d9pCtqvupyL5gtegw+/L9IVyMiIhJR4Ww5OwJY65xb75yrAp4Epu13zEjgXf/xe/X2nwq85Zzb5ZzbDbwFnBbGWjs+Mzj9d7jDzuWX8U+w9s37+GjtzkhX1Twf/wWKvoJ+E+Dfv4dtyyNdkYiISMSEM5z1B+qvL5Tnb6tvMXCu/3g6kGpmvZr5WtlfTAw2/V4CgydzV/x9PP34/eQXlke6qqYVb4YPfw8jzoaLn4WkdHjpOggGIl2ZiIhIRER6QMBPgBPM7HPgBCAfaPa/ymZ2pZktMLMFO3bsCFeNHUtcArEXPUp1n9HcFfg//vyvh6mojuKg8/ZvIVgD37gVUnrBaXdB/kL4z32RrkxERCQiwhnO8oEB9Z7n+NvqOOc2O+fOdc6NB37lbytszmv9Y+9zzk1yzk3KzMwMcfkdWGIqSZc+TyC1P78ovJl7nn4p0hU1bNN8WPIkHH0t9BzibRs9Aw49Bd65FXZvjGx9IiIiERDOcDYfONTMhphZAnAhsE9KMLPeZlZbwy+AB/zHc4BTzCzDHwhwir9NmiulNynfe5mYhBQuXHMDL3/wcaQr2lcwCG/cCN2z4Lgf791uBmf+3nv8yg3Q0UadioiItFHYwplzrga4Fi9UrQSeds4tN7NbzGyqf9hkYLWZrQGygNv91+4CbsULePOBW/xt0hI9BtLtuy+SGlPNYe9exvIv1kW6or2WPu11X558MySm7ruvxwA4+SZY9w4seToi5YmIiESKdbj5sBoxadIkt2DBgkiXEZWKV39I4hPnst4GknX9W/TM6BnZgipL4c8TIa0ffO8diGng/xGCAXjgNChYC9fOh5Te7V+niIhImJjZQufcpIb2RXpAgLSDtNzj2HLKPRwaXE/+PecSqIrwRK///gOUboXT72o4mAHExMLUWVBZAm/8on3rExERiSCFsy5i8DHnsXDcrYyu/Jw1914cuakqdm+AeX+G0RfAgCOaPrbPCDjuv7wu0C/eapfyREREIk3hrAs5cvq1vNb3+4woeJuNj10bmYvt3/qN1yp28s3NO/64H0PmcHj5R14rmoiISCencNbFnPTd23g++TwGrXucgtdua983//JDWPEifP0GSG/mnMJxiTD1z1CcD++2c70iIiIRoHDWxSTGxXLUlX/hZZtMr/l3U/Hx/e3zxsGAd+1Y+gA45rqWvXbAEXDEFfDpvbDpP+GpT0REJEoonHVB/TK60fuie3gnMJ6EOT9l19x2mI3/s4dh21L4xi0Qn9zy15/0G0jr7y3tVFMV+vpERESihMJZF3X0sL7knfx33g+Mpee7P+XB39/Iswvz2FNZE/o3Ky+Ed2+FgcfAYdNbd47EVDjr97BjlTfaU0REpJNSOOvCLj1hBMN++CJre01hZvE9rHv+Vg6//W3+6+nFfLyugGAwRAMG5v4vlO2C0+/0VgBorWGnwqgZ3vm2rwpNbSIiIlFG4ayLy+ndg699/1nc6PO5Mf5J/pz9GnOWb+Gi+z/h+P99j9+/tYaNBXta/wY7v4BP74EJ34a+Y9te8Gl3QmJ3ePl6bwmoaLV7A9xzHHxyT6QrERGRDkbhTCA2Dpt+L4y/hJO2P8TnR33In745liG9U/jzu19wwv++zwX3fszT8zdR2tJuzzm/hLhkOPHXoam1e6YX0DZ9Cgv+GZpzhtrujfDg2bB1Ccz5Bax/P9IViYhIB6JwJp6YWDj7z3D4FcR/+hembf4Dj1x2OB/deCI/PTWXnSWV/Oy5JRx+29v8+KlFzFu78+Ddnl+8BV+8CSf8DLr3CV2tY74Jh5wIb98MRXmhO28oFH4FD50FlcVw2evQexg8e3n01SkiIlFLa2vKvpzzJoqdNwvGXwJnz4KYWJxzfPZVIc8uzOOVJZspqaihf49kzp3Qn/Mm5DC4d8q+5wlUw9+PgWANfP9TiEsIbZ27N8LfjoIhx8NFT7btWrZQKcqDf50BFYXwnReh33jYsQbuPxEyh3lhLS4x0lWKiEgU0Nqa0nxm3nQXJ/wcPn8Unr8SAtWYGRMHZXDHuaOZ/6uTmXXReA7p052/vreWyXe/zy9fWEp1oN41YPP/ATvXwKn/E/pgBpAxyOsqXfMGLHsu9OdvqaJ8ePAsb2Tqt1/wghl4oeycv0H+Qq0RKiIizRIX6QIkCpnBlF9AfJLXdVhTATMeqGv1SYqPZerYfkwd24+tRRXc/+F6/vnvL9m0q4y/XjyBtEAxvH+H1/U47LTw1XnkVbD0GXj9Ru+9uvUM33s1pXgzPHQ2lBV4waz/xH33j5wKx/4QPvoT5EyCcd+KTJ0iItIhqOVMGvf1G+D038GqV+DJi6G6/IBDstOT+PVZI/ndjDF8vK6A8/42j9I3fguVpXDqHeHtboyJ9ZZ2qiiEOb8K3/s0pWSrF8xKt8Elz3nhqyEn/gYGHwev3ABblrRvjYFq+GiWBiaIiHQQCmfStCOv8q47W/s2PHa+F7oacMGkATx8+RGkFa8meekj7BjxbegzPPz1ZY/yQuTix2HtO+F/v/pKtnldmcVbvGA24IjGj42N81ofk3vC09+G8t3tU2NVGTx1Cbz1a3h4GjxyLmxd2j7vLSIiraJwJgc38VI49z7YOA8ePRcqiho87JhDevFI/xcopRtnLf06ry/d0j71HfcT6HUovPIjqGrDnGwtUbrdazEr3gyXPAsDjzr4a7r3gQse8q5Pe/6q8M/TVl7o/XmtmeO1gJ5yu3ft2z3HwQtXQ+Gm8L6/iIi0isKZNM+YC+D8f3n/uD801Zvxf3+rXqFb/jxiT/oV/fr24/uPf8a9H6wj7COC45Ng6ixvGov3/ie87wVQusP7Doo2wcXPwKBjmv/aAUfAaXfAF3Pgw7vDV2PJVm/kaN4Cr8XuyKvgmGvhh4u8heeXPQ9/nuiNzC0vDF8dIiLSYgpn0nwjp8GFj8P2lV53XumOvfuqK7zrvjJH0P2YK3niiqM4Y3Rf7nh9Fb98Ydm+IznDYdAxMOly+ORvsPwFCAbC8z57dsLDU70VAL71NAw+tuXnOPx73lxt7/2P110cagXr4J+neDVe/DSMOnfvvuQMOOVWuG6ht/2jWTBrHMz7C9RUhr4WERFpMYUzaZlhp8K3noJd6+HBM7xuPfBCUeFGr1UoNo6k+Fj+fOF4vj/5EJ74z1dc/uB8iiuqw1vbyb+FnkPhmZkwa7w3OnJPQejOv6fAu25r13r41pMw5LjWnccMzvojZB0Gz33Pm7MtVLYsgQdOg8oSuPRlbxRrQ3oMgOn3wNUfQr8J8Oav4C+TYMkz0b0slohIF6BJaKV1Ns6Dxy6AlF5w7v3w8DkwdDJc9PgBhz49fxO/fGEpQzNTeGDm4eRkdAtfXTVV3ujS+f+AjR9BbKLXQnT497wpLlo7erRsl9ditmONF8waCz0tUbAO7psCPYfA5XO87tm22PBveOIiSEz1pvTIzG3+a9e963Vxbl3qrYH6jVu8P08REQmLpiahVTiT1stbCI9Oh4piiImDH3wKvQ5p8NCP1u7k6kcXkhgXyz8vncTYAT3CX9+2Fd76m4ufhKpS6DvOC2mjzoOEFgTE8t3eNWY7Vnvh82snh67GVa/BkxfBhO9404K05TzPzPQm5/32C5Ce0/JzBIOw7Fl451Yo+sr7nCf/1hsRKyIiIaVwJuGzZQk8/k2YOBMm39jkoV9sK+GyB+ezs7SSP35zPKeNym6fGiuKYclTXmvajlWQ1MNbmmrS5Y2GyTrlhV5X5vYVcOETcGgIg1mtd271BgecPcsbGdtSnz8GL10H/cbBxc+2fTLe6gqYfz/MvdsbmTvuWzDll60LfCIi0iCFMwmvYBBimnf54o6SSq54eAGL8wr55ekj+N5xQ7D2WhfTOa+rc/4/YOXL3rqfh5wIh1/hXUsXE7vv8eWF8Mh0r6vvwse8Y8IhGIBHz/O6ir87Z+/ST83x0Z+87shDToQLHoHE7qGrq3w3fPh7+PRerzv4yKu9OeWSe4TuPUREuiiFM4kqFdUBfvz0Il5bupVvHTmQW6YeRlxsO49NKdkKCx+Chf+Cki2QPsBr/ZvwHW8+sopiL5htWQzffARyTw9vPXsK4L4TAIOrPjh461f9BeoPOxem3xueNUzBm6Lk3du91sfuWV6AzBgcnvcSEekiFM4k6gSDjv99czV/f38dxw/L5K/fGk9qUnz7FxKohtWve914X86FmHg47BxvGorNn8MFD8PwM9unlvyF3kjLwcd586ft35JXV3MNvPxDWPSodw3d6b9r/NhQ1/fIuZDSGy5/0xsMIiIirdJUONNUGhIRMTHGjacN585zR/PR2p2cf8/H5BceuHZn2MXGewuTX/oy/OA/cPh3vRn1N38O5z/YfsEMvNGkp/8O1r0D79/Z8DHV5fD0d7xgNvkXcMbd7RPMauv71lPeygJPXOgtDSUiIiGnljOJuH9/sZNrHl1ITIxx7oT+nD9xACP7pUWuoMpSKNsZma475+DFa73wddFTkHva3n0VRd5UGRvnwRn/C0dc0f71Aax4yQuIw8/0WhbbKxyKiHQi6taUqLd2ewm/f2sNb63YRnXAMap/GudPHMC0cf3o0S1M11JFq+pyb4b/wo1w5fvexLql2711Mrev8iaPHT0jsjV+ei+8/jOvW/WMu1s/f5yISBelcCYdxu49Vby4KJ9nFuaxfHMxCbExfGNkFjMm5XD8oZnExnSRELB7A9x7gjdQ4bz7vRaz0m3wzUfhaydFujrPm7/2BiScdBMc9+NIVyMi0qEonEmHtGJzMc8s3MTsz/PZXVZNVloi507I4fyJOQzNDOGUEdHqi7fgsfO9VqmkdG8Os5wG/zuOjGAQnr/Cm7h2+n0w9puRrkhEpMNQOJMOraomyLurtvHMgjzeX7ODQNAxcVAG50/M4cwxfSMzyrO9fPQnWPQ4nP8Q9Bke6WoOVFPpzdH21SdwybNa8klEpJkUzqTT2F5cwfOf5/PMgk2s27GH5PhYTh+VzYxJORw1pBcxXaXbM5qUF8K/TvdGcV7+OmSPjnRFzbN5EXxwFySkQP9JXqtk9miIS4x0ZSLSBSicSafjnOPzTYU8syCPVxZvpqSyhgE9kzlvQg4zJuaEd3F1OVBRPvzzG+CC8N23oMeASFfUuMoSb1Ld/9wLyRkQm+BNRAze4+zRe8Na/4negAwNeBCREFM4k06tvCrAnOVbeWbhJj5aW4AZHHNIL2ZMzOG0w/qSnKCpHtrFthXeJLqp2d4qAskZka5oX855y3a9fqMXxiZdDif9xluOqigf8hdA3gJvst3Nn0O1P49bcoYX0uoHtrauXyoiXZ7CmXQZebvLeG5hPs9+tolNu8pJTYzjrLF9mTFxABMG9mi/dTy7qi8/9Kb86D8Jvv0CxCdFuiJP4Vfw2k9hzRuQNQrO+iMMOLzx4wM1sGPVvoFt+0rA//uy59B6YW0SZI9Sd6iItIjCmXQ5waDj0y938czCTby+dCvl1QGGZqYwY2IO503IISstSkJDZ7T0WXjuuzDyHJjxL4iJ4EIkgWr45G97V1yY8ks48hqIjWv5uSpLvBa12rCWv3Bvd2hMPPQZAX3H+rdxkHUYJKh7XUQapnAmXVppZQ2vLdnCMws3MX/DbmIMjh+WyfkTB3DyyD4kxqnbM+Tm/Rne/G846vtw2h2RqWHTf+DlH8H25ZB7hrc0VqivhavtDs3/DLYu8QYZlO/y9lkM9M6tF9jGeNezJaWHtgYR6ZAUzkR8X+7cw7MLN/H8Z/lsKaqgR7d4po3tx/mTBnBYvzR1e4aKc/DGL+DTv8Mpt8Mx17bfe5fvhrd/CwsfhLR+XigbcVb7vLdzUJwPWxbve6ttYQOvS7QusI2F7LEHX0S+pspruass8u4riv3n/n1F0d7nyT1h0mWQnhPezyoibaJwJrKfQNDx0dqdPLMwjznLt1JVE2R4diozJuYwfXx/enXX9UNtFgzCszNhxYsw4wEYdV543885r0t1zi+grMDrvpzyC0hMDe/7NkfJNq9lbcuivYGt8Ku9+9MHeNfCxcR6AWv/8FVTcfD3iImHpDRvahMzGDUDjr3e614VkaijcCbShKKyal5asplnF2xicV4RcTHGicP7cP6kAUzOzSQ+NoLXTHV01RXwyHSv6++S52HIceF5n4J18OqPYf370G8CnP1Hr1UqmpXt8gPbYtiyBLYt90JVYpoXKJP8+8Q077bP89r9aXuf1w6+KPwKPvk7LHwIqvfA106GY66HIcdrShCRKKJwJtJMa7aV8MyCTbzw+WZ2llbSu3sC54zrz4xJOQzPTot0eR1T2S5vio2SrXD5G5A1MnTnrqn0VlGYe7c3WvKk33hTZMToOkLKd8P8f3qL1O/Z7g1SOPZ6GDGtdQMiRCSkFM5EWqg6EOSD1Tt4dmEe76zaRnXAMbp/OjMm5jBtXD96dEuIdIkdS+Em+MfJXmj67luQ3r/t5/zyQ3jlBij4Ag6bDqfeAWl9237ezqa6ApY86Q3SKFgLPQbB0dfC+Iu91RE6s5pKrzV1xUtQstkbkNF3HPQbBxlD1JIoEaVwJtIGu/ZU8eKifJ5ZkMeKLcUkxMZw8sg+nD9xAMcd2ps4dXs2z9al8MDp0GMgnPAz7zqq6jIvPNSUe/fVZf722m3+raFj92z3gsaZv4dDT470p4t+wSCsfg3mzYJNn3qT6x5xpXdL6R3p6kKnuhzWvuNd67jmDe+6vcQ077eyYxUEq73jktL3TnvSb5x3r9UgpB0pnImEyPLNRTy7MI8XF21m154q+qQmMn1Cf86fmMPX+kTBhefRbv378OiMvf9A7i++G8QlQXyyf9/Nu5Zqn8fJ3n3GEC9YaC6xlvvqE/holhfW4hJh3Le81rReh0S6stapLIUv3oSVL8GaN71r7ZIzIPdMGDkNhp7gfc6aSti+wpvyZMsi7377CghUeedJTPemPKkNa/3Ge7+zSM7VF+1qqmDduzD42OgYfNOBKJyJhFhVTZB3V23n2YWbeG/1DgJBx7gBPZgxMYezx/YjPTk+0iVGr+It3lxg+weuuES1WrS3nV943Z2Ln/Am7B1xNhz7Q2/lg2hXUQSr3/AC2dq3vdbVlEwYfhaMnAqDj4PYZvx3WFPlBbTasLZlkTc4oy6wpe07uXDPIZDWH7r36drXNgaDsPx5ePdW2L0BMgbDuf9oeuUN2UfEwpmZnQb8CYgF/uGcu3O//QOBh4Ae/jE/d869ZmaDgZXAav/QT5xzVzf1XgpnEik7SiqZ/Xk+zyzcxJptpSTGxXDqYdnMmJjDkUN7apJbiX4l27yF4Of/wws9A4+Gnod4ASVQBcEa/3G1f6vyWj/rPw9U+9uqvOWvAlVeOErt6803l9bfuyaw7nE/SO0H3Xo1v2WqbJfX2rfiRVj3nvd+qX1hxFQvkA08OjSBqaYKdqzct4Vt23IIVO49JiZuv8/m36f395930gDnHKx7x5tLcOsSbwqYSZd5A3OK8uGEG+G4/9Kgk2aISDgzs1hgDfANIA+YD1zknFtR75j7gM+dc383s5HAa865wX44e8U5N6q576dwJpHmnGNp/t5uz6LyamJjjCG9U8jNTmV4VirDslMZnp3KgIxuxMREZyuRc46CPVV8tauMTf7Ne1xOeXWAw/qlMTanB6Nz0jm0T3ddc9eZVJbAZ494E/hW7fH+gY1N8OZQi433Hsf6j2Nqn/vHxCZ4gaX+MTWVULzZm4S39t4F933P2AQ/5DQS3pIzYMNc76L+L+eCC0D6QC+MjZzmrW3aHt2OgWrYucYb3FKc532e4s1QVPs4/8D56CzW+2zp9cJbWn/oM7z5LXvRJG8hvH0TbPjQu4bvxP/25tOLifFC/Ws/hSVPwYAjYfq9Xitje3EOVsz2WoKr9gDmrdJh5j+uvcXsu6/B53if75y/hrXkSIWzo4GbnXOn+s9/AeCcu6PeMfcC651zd/nH/59z7hiFM+noKqoDfLBmB0vzili1tYQ120r4aldZ3f7k+FiGZXUnNzuVYVmpDM9OIzc7ld7dE9pllYLyqgB5u73QVRu86sLY7jLKqgL7HJ+ZmsjAnt2IizFWbC6mpLIGgKT4GA7rl86YnNpbD4b0Sona4CkRFqjxBnIUb/HCTG2oqQ1vtdtquxTr6znUC2Mjp3ndi9HWBe6cN31Jcb7XglScv+9nLPIf15R7xyf39D7LqPNg0DHR3cK28wt45xavC7lbb29Az8TLIK6BUetLn4VXfuyF8DP+F8ZeGP4/q7yF3uTTmz6FzOGQmev9edT+j4AL1nvumnju9j5PHwDn3R/WsiMVzmYApznnvuc//zZwpHPu2nrH9AXeBDKAFOBk59xCP5wtx2t5Kwb+2zn3YQPvcSVwJcDAgQMnbty4MSyfRSQU9lTW8MX2UlZvLa4LbKu3lrCzdO8/RD1TEsjNSiU3e+8tJyOZmoCjOhCkqiZIZU2w7nF1wFEVCFBVE6Qq4Lz7evur6r1mW3FFXRjbUVK5T23dEmIZkNGNAT27MbBnNwb0TGag/zgnoxvJCXv/4QgGHRsK9rAkr8i/FbJscxEV1d5fhKmJcYzqvzesjclJJycjWUtjSfM453Vf1gabPdu9iYWzDou+QNZStQHuq09g2XNeF211GXTP8qaDOexcyDk8egYgFG+G9++Ezx/1Bukccx0c/YODX/hf+BW8cDVs/Mj7XGf9wWsBDbXCTV5oXPo0pPSBk34N4y6O7qBbTzSHsx/7Nfyf33L2T2AUEA90d84VmNlEYDZwmHOuuLH3U8uZdFQ7SytZs7WkLrDV3u/fetUW8bFGn9SkfYLXgJ57w1ivlLa12NUEgqzdUcqSvCKW+oFt5ZYSqgJeYMvoFs/onB6MzUlndP90Jg7K0BJZIlV7YM0c78L6NW9617SlD/ACzajzvEEIkQik5bvh33+ET++BYMCb2Pn4n0L3zOafIxiAj/4I7/2PFz6n3xu6FUIqS71zz/uz9/zoa+HrP+pwo0WjuVtzOV6A2+Q/Xw8c5Zzbvt+53gd+4pxrNH0pnElnEgw68gvLWb21hC1F5cTHxpAQ593qHsfWe37ANttnXyS6GatqgqzeWsKS/EKWbCpiSX4Ra7aVEAh6f+cMy+rOkUN6ceTQnhw5pBeZqQpr0oVVFHstacue9y64D9Z4XbmjzvNufUaEv4bqcm9FiX//wbuGbPT5MOWXbbt2LP8zeP4Kb4m1Y38IU37VcHdocwQDsOgxePc2KN3m1XfSTdBjQOvri6BIhbM4vG7Jk4B8vAEB33LOLa93zOvAU865B81sBPAO0B/oDexyzgXMbCjwITDaObersfdTOBOJfhXVAZZvLuLTL3fx6fpdLNiwiz1+C+EhmSkcObQXRw3txVFDetInLSnC1TatOuB1FW8urKC0spqMbgn07p5Iz5QEuiXEqhtXWq9sF6x82WtR+3Kudw1U5gg/qJ0b+vnoAjWw+HF47w5vJYWvfQNOvslbUSEUqvbAnF96A036jvWm3Mgc1rJzrP8A5vwKti31Bhyc+j8dY8qXJkRyKo0zgD/iTZPxgHPudjO7BVjgnHvJH6F5P9AdcMDPnHNvmtl5wC1ANRAEbnLOvdzUeymciXQ8NYEgyzYX8+n6Aj5ZX8CCDbvrBhsM6Z3CUX6r2pFDe9I3Pbnd6nLOUVReTX5hOZsLK9hcWM7mwnL/ubdte0kFwUb++kyMi6FXSgI9uyfQMyWRXikJdc97pXjbevrbenVPoHtinMKcNKx0uzd1yLLn4at53ra+Y2HkOZCes+8I2X0ex+832nbfx0GLZ96GIrp/9S5j18zCdq7xRr5+47cw+Ovh+SyrXoUXr/Va6E693esuPdjvfucX8OavYc3r3uoiJ//W6/btBP+9aBJaEekQagJBVmwp5tP1u/j0ywI+/XIXJRVeWBvUqxtHDvHC2lGH9KJ/j33DWjDoqA4GqQk4bwBF0BsYUTuYoibo3VcHHDX+fXUgyPaSygbDV3n1vtf8JcTF0C89iX49kvfe/Ofdk+LYvaeKgj1V7NpTRUFpZd1j77l3v/85684dG0Ov7gkM7pXC8L6pjPBH7w7LSt1nMIZ0cUV5sHy216KWvzBkp90Um0PVCf/NIce1w8jKkq0w+xpvVYFhp8PUPzd8LVvZLvjgLm/uvbhkOP6/4MhrvEmrOwmFMxHpkAJBx8otxXyy3gtq//lyF0Xl3tJPqUlxOIcfuIKNtmI1V+/uifTvsW/4qn3eNz2ZXikJbb52r7wqQMGeyrqw5gU4L8jtLKli7Y5S1mwtqQtxZniBLXvvdCsj+kb3PHnSTkq3e9ep1Z8MOLjffb3H2wpL+PiLbSzbuINgoJpBPeI5YmB3SpL686NlQ9hcUsPUsf248fThB/yPT8gFg96kx2/d5K1xes7f4NBvePtqqrxA9sFd3rqoE2fC5F+2bDBCB6FwJiKdQjDoWLW1hE+/LODLnXuIi/EGP8TFGnEx3mCIuBgjLtbf7u+Pj42pO6b+84TYGDJTE8lOT4qalRwCQcdXu8pYvbWYlVu86VZWbS1m464yav+67pYQy7AsL6jlZqUyvG8aw7NT6dGtlRdaS6cUCDreWbmNhz7ewEdrC0iIi+HsMf249JhBjMnpUXdcWVUN97y/jnvnrscMrjz+EK4+YSjdEsI8y/+25fDc97zls464yluf8+2bYdd6OOREOOV2yBoZ3hoiSOFMRKSDK6uqYc22UlZt8ebJW+XPl1dYtncR+ey0JAb0TCY2xogx/xZjxBj+czAzYs2IifEe126P2e+xw3nzclI7P6fzH7u6bUH/MQ4cjmCQfV6XmhTHmP7pjBuYwYi+qVETgFurrKqG5PjoH+yxe08VTy3YxCMfbyS/sJx+6UlcfNQgLjx8QJNT2OQXlnPn66t4efFmstOSuPH0XKaN7R/eVtrqCnjnt/DJ37znmcO9UHboyeF7zyihcCYi0gk559heUsnKLcV+C1sJmwvLcXitjEHnCPrBKuiHqUDQ1QWroPMeB/zHwaB3bMA5DMP8oAb1Vr9hb8gz8Fa+wTuudn9tdinYU1U34XFCbAwj+qUxLiedsQN6MG5ADwZH0WoSFdUBthTtHfyxpaiCLUXl5BdWsMV/XlpZQ1J8jD9BcwqDenVjUK9u+0zYnBAXuQlkl28u4qF5G3hx0WYqa4IcNbQnM48ZzMkjslq0zNrCjbv47csrWJJXxLgBPfjN2SOZMDAMk8jW9+Vcb1LZMd/sMutyKpyJiEi7c86xpaiCxZsKWZRXyKKvClmaX1Q3wXJaUlxdUBub04OxA3qEZb67iuoABXuq2OIP+thS5AWuzX4Y21JUwa49By4Z1bt7gn/NYRJ905Ppk5ZIQWkVGwvK+GrXHr7aVVa3MgZAjEHf9OR6oS1lb3jr1Y20pNCvpVkdCPLGsq08NG8DCzbuJjk+lukT+nPp0YPJzW79pKzBoOOFz/O5641VbC+pZNq4ftx42nD6hft6tC5E4UxERKJCIOhYu72URZt2s2hTEYs3FbK63uTE/Xske2FtQDrjBmQwqn8aMWYUV1RTXF7j31dTXFHj3x98e1VN8IA6UpPi6F8bvOqNvO2bnky/HklkpSWRFN90N2xty+VXu8q8wFawh421j3eVHRD4MrrFM7BXCtlpiSTFx5IcH0tSfCyJ8TF1j5PiYrx9CbEkxsWSVH9f3WtiqAoEeW5hPo99upHtJZUM6tWNbx81iPMnDSA9OXQhcE9lDfd8sI77/OvRrjr+EK5qj+vRugCFMxERiVplVTUs31zstbD5t7zd5c1+fUJsDGnJ8aQlx5GWFO89Torz773tGd0S6qY/6dsjme6J4Q8XJRXV3nq2BWV1oW2Tv7ZtRU2AiuoAFdVByqsDDQbI5jhhWCYzjxnMCcMyw9pFnLe7jDtfX8UrS7aQnZbEz08fztSx/Vr8noGgY3NhOV/tKmNDwR42FpSx0b+vCTpvRHJ2KrnZ3iCXzrwur8KZiIh0KDtLK1mSV8jy/GJiYuyAwJVeL4wdrIWrIwgGHZU1XlCr8G/lfnirrPe4dntNIMjxwzIZmtm9Xeucv2EXt7y8gqX5jV+PVlUTZNNuL5TuH8A27S6jOrA3dyTEedfwDerZDTNj9bZiNu3aG8xTE+MYlp3qTSfjj0rOzU4NSxcxeK2hJZU1VFQFwr5KicKZiIiIhEQw6Hjuszx+N2c1O0oqOXNMX9KT4+sC2ObC8n3mHUxJiGVQrxQG9/auwxvcy7sGb3CvFLLTkg5ofSupqGbNNm+Ay6ote0cm105IDV73txfYvDkAh2enMqR3yj4DHwJBb6WP3WVVFJZVsWvPvo8Ly6rYXVbFbn/77jJvW03QkZuVypwbjg/r96hwJiIiIiFVWlnD399fyz///SXJ8V4A8wZDeAGs9nGvlIQ2d00659hcVFE3/9+qrSWs3lrMuh176q5XTIiLYUivFKoCQXaXVVFUXk1jESc+1ujRLYGe3RLo0S2ejG4JZKQkkOE/7tcjmTPH9G1TzQejcCYiIiJhEQy6iE2JUlkTYO320rqpZNbvKCUpPtYLW93i/cDlBbCe9R5Hw3q2TYUzDbcQERGRVovkXHWJcbEc1i+dw/qlR6yGcIjcbHkiIiIicgCFMxEREZEoonAmIiIiEkUUzkRERESiiMKZiIiISBRROBMRERGJIgpnIiIiIlFE4UxEREQkiiiciYiIiEQRhTMRERGRKKJwJiIiIhJFFM5EREREoojCmYiIiEgUMedcpGsICTPbAWxs4pDewM52Kqcr0vcbPvpuw0vfb/jouw0vfb/h0x7f7SDnXGZDOzpNODsYM1vgnJsU6To6K32/4aPvNrz0/YaPvtvw0vcbPpH+btWtKSIiIhJFFM5EREREokhXCmf3RbqATk7fb/jouw0vfb/ho+82vPT9hk9Ev9suc82ZiIiISEfQlVrORERERKJelwhnZnaama02s7Vm9vNI19OZmNkGM1tqZovMbEGk6+nozOwBM9tuZsvqbetpZm+Z2Rf+fUYka+yoGvlubzazfP/3u8jMzohkjR2ZmQ0ws/fMbIWZLTezH/rb9fttoya+W/1+Q8DMkszsP2a22P9+f+tvH2Jmn/rZ4SkzS2i3mjp7t6aZxQJrgG8AecB84CLn3IqIFtZJmNkGYJJzTnPthICZHQ+UAg8750b5234H7HLO3en/z0WGc+7GSNbZETXy3d4MlDrn7o5kbZ2BmfUF+jrnPjOzVGAhcA4wE/1+26SJ7/YC9PttMzMzIMU5V2pm8cC/gR8CPwaed849aWb3AIudc39vj5q6QsvZEcBa59x651wV8CQwLcI1iTTIOTcX2LXf5mnAQ/7jh/D+UpYWauS7lRBxzm1xzn3mPy4BVgL90e+3zZr4biUEnKfUfxrv3xxwIvCsv71df7tdIZz1BzbVe56HftSh5IA3zWyhmV0Z6WI6qSzn3Bb/8VYgK5LFdELXmtkSv9tTXW4hYGaDgfHAp+j3G1L7fbeg329ImFmsmS0CtgNvAeuAQudcjX9Iu2aHrhDOJLy+7pybAJwO/MDvOpIwcd51CJ37WoT29XfgEGAcsAX4v4hW0wmYWXfgOeBHzrni+vv0+22bBr5b/X5DxDkXcM6NA3LwetyGR7KerhDO8oEB9Z7n+NskBJxz+f79duAFvB+1hNY2/5qT2mtPtke4nk7DObfN/0s5CNyPfr9t4l+v8xzwmHPueX+zfr8h0NB3q99v6DnnCoH3gKOBHmYW5+9q1+zQFcLZfOBQf9RFAnAh8FKEa+oUzCzFvzgVM0sBTgGWNf0qaYWXgEv9x5cCL0awlk6lNjT4pqPfb6v5F1X/E1jpnPt9vV36/bZRY9+tfr+hYWaZZtbDf5yMN4BwJV5Im+Ef1q6/3U4/WhPAH178RyAWeMA5d3tkK+oczGwoXmsZQBzwuL7btjGzJ4DJQG9gG3ATMBt4GhgIbAQucM7pwvYWauS7nYzXJeSADcBV9a6PkhYws68DHwJLgaC/+Zd410bp99sGTXy3F6Hfb5uZ2Ri8C/5j8RqtnnbO3eL/G/ck0BP4HLjEOVfZLjV1hXAmIiIi0lF0hW5NERERkQ5D4UxEREQkiiiciYiIiEQRhTMRERGRKKJwJiIiIhJFFM5EpFMzs4CZLap3+3kIzz3YzDS3lIiEVNzBDxER6dDK/WVZREQ6BLWciUiXZGYbzOx3ZrbUzP5jZl/ztw82s3f9xaTfMbOB/vYsM3vBzBb7t2P8U8Wa2f1mttzM3vRnGMfMrjezFf55nozQxxSRDkjhTEQ6u+T9ujW/WW9fkXNuNPAXvFVEAP4MPOScGwM8Bszyt88CPnDOjQUmAMv97YcCf3XOHQYUAuf5238OjPfPc3V4PpqIdEZaIUBEOjUzK3XOdW9g+wbgROfcen9R6a3OuV5mthPo65yr9rdvcc71NrMdQE795VvMbDDwlnPuUP/5jUC8c+42M3sDKMVbfmu2c640zB9VRDoJtZyJSFfmGnncEvXX2guw91reM4G/4rWyzTczXeMrIs2icCYiXdk3691/7D+eB1zoP74Yb8FpgHeAawDMLNbM0hs7qZnFAAOcc+8BNwLpwAGtdyIiDdH/yYlIZ5dsZovqPX/DOVc7nUaGmS3Ba/26yN92HfAvM/spsAO4zN/+Q+A+M/suXgvZNcCWRt4zFnjUD3AGzHLOFYbo84hIJ6drzkSkS/KvOZvknNsZ6VpEROpTt6aIiIhIFFHLmYiIiEgUUcuZiIiISBRROBMRERGJIgpnIiIiIlFE4UxEREQkiiiciYiIiEQRhTMRERGRKPL/wPwFRix5+poAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#with new weighted loss\n",
    "epochs = list(range(1, 31))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_losses, label=\"Training Loss\")\n",
    "plt.plot(epochs, val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs. Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cc301db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(pred, target, num_classes=3):\n",
    "    \"\"\"\n",
    "    Compute the Intersection over Union (IoU) for each class.\n",
    "    Args:\n",
    "      pred (torch.Tensor): Predicted tensor of shape (N, H, W)\n",
    "      target (torch.Tensor): Ground truth tensor of shape (N, H, W)\n",
    "      num_classes (int): Number of classes.\n",
    "    Returns:\n",
    "      list: IoU for each class.\n",
    "    \"\"\"\n",
    "    ious = []\n",
    "    # Flatten the tensors for easier computation.\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = (pred == cls)\n",
    "        target_inds = (target == cls)\n",
    "        intersection = (pred_inds & target_inds).sum().float()\n",
    "        union = pred_inds.sum().float() + target_inds.sum().float() - intersection\n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))  # Alternatively, you might want to append 0.0\n",
    "        else:\n",
    "            ious.append((intersection / union).item())\n",
    "    return ious\n",
    "\n",
    "def compute_dice(pred, target, num_classes=3):\n",
    "    \"\"\"\n",
    "    Compute the Dice coefficient for each class.\n",
    "    Args:\n",
    "      pred (torch.Tensor): Predicted tensor of shape (N, H, W)\n",
    "      target (torch.Tensor): Ground truth tensor of shape (N, H, W)\n",
    "      num_classes (int): Number of classes.\n",
    "    Returns:\n",
    "      list: Dice coefficient for each class.\n",
    "    \"\"\"\n",
    "    dices = []\n",
    "    # Flatten the tensors.\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = (pred == cls)\n",
    "        target_inds = (target == cls)\n",
    "        intersection = (pred_inds & target_inds).sum().float()\n",
    "        total = pred_inds.sum().float() + target_inds.sum().float()\n",
    "        if total == 0:\n",
    "            dices.append(float('nan'))\n",
    "        else:\n",
    "            dices.append((2 * intersection / total).item())\n",
    "    return dices\n",
    "\n",
    "def compute_confusion_matrix(pred, target, num_classes=3):\n",
    "    \"\"\"\n",
    "    Compute a confusion matrix where the rows correspond to true classes\n",
    "    and the columns correspond to predicted classes.\n",
    "    Args:\n",
    "      pred (torch.Tensor): Predicted tensor of shape (N, H, W)\n",
    "      target (torch.Tensor): Ground truth tensor of shape (N, H, W)\n",
    "      num_classes (int): Number of classes.\n",
    "    Returns:\n",
    "      torch.Tensor: A (num_classes, num_classes) confusion matrix.\n",
    "    \"\"\"\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "    # Use torch.bincount to count occurrences of each (true, pred) pair.\n",
    "    cm = torch.bincount(num_classes * target + pred, minlength=num_classes**2)\n",
    "    cm = cm.reshape(num_classes, num_classes)\n",
    "    return cm\n",
    "\n",
    "def compute_precision_recall_f1(conf_matrix):\n",
    "    \"\"\"\n",
    "    Compute per-class precision, recall, and F1 score from a confusion matrix.\n",
    "    Args:\n",
    "      conf_matrix (torch.Tensor): A (num_classes, num_classes) confusion matrix.\n",
    "    Returns:\n",
    "      tuple: Three lists containing precision, recall, and F1 score for each class.\n",
    "    \"\"\"\n",
    "    num_classes = conf_matrix.shape[0]\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    for i in range(num_classes):\n",
    "        TP = conf_matrix[i, i].item()\n",
    "        FP = conf_matrix[:, i].sum().item() - TP\n",
    "        FN = conf_matrix[i, :].sum().item() - TP\n",
    "        \n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else float('nan')\n",
    "        recall    = TP / (TP + FN) if (TP + FN) > 0 else float('nan')\n",
    "        f1        = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else float('nan')\n",
    "        \n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "    return precisions, recalls, f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d1a0524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.8738\n",
      "torch.Size([366, 120, 120])\n",
      "torch.Size([366, 120, 120])\n",
      "IoU per class: [0.435091108083725, 0.017175473272800446, 0.01975046657025814]\n",
      "Dice per class: [0.6063602566719055, 0.03377091512084007, 0.03873588144779205]\n",
      "Confusion Matrix:\n",
      " tensor([[2244518,  433006, 2387351],\n",
      "        [  39761,    9175,   40957],\n",
      "        [  54095,   11293,   50244]])\n",
      "Precision per class: [0.9598627080184778, 0.020232692502767522, 0.020271513367482303]\n",
      "Recall per class: [0.4431536809891656, 0.10206578932731136, 0.43451639684516397]\n",
      "F1 per class: [0.6063602615554332, 0.033770913581428384, 0.03873587995300256]\n"
     ]
    }
   ],
   "source": [
    "# with new weighted loss\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs in test_loader:\n",
    "        labels = inputs[-1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        veg = model_veg(inputs[0])\n",
    "        elevation = model_elevation(inputs[1].squeeze(1))\n",
    "        era = model_ERA(inputs[3])\n",
    "        solus = model_solus(inputs[2])\n",
    "        \n",
    "        outputs = model(torch.stack((veg, elevation, era, solus), dim=1))      # shape: (B, 3, 120, 120)\n",
    "        \n",
    "        loss = criterion(outputs, labels, spatial_mask)\n",
    "        test_loss += loss.item() * inputs[0].size(0)\n",
    "        \n",
    "        # Convert raw logits to predicted class labels (shape: (batch_size, H, W))\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        # Collect predictions and ground truth labels for metric computations\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "\n",
    "# Calculate average test loss over the dataset\n",
    "test_loss = test_loss / len(test_dataset)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Concatenate all the collected predictions and labels along the batch dimension\n",
    "all_preds = torch.cat(all_preds, dim=0)\n",
    "print(all_preds.shape)\n",
    "all_labels = torch.cat(all_labels, dim=0)\n",
    "print(all_labels.shape)\n",
    "\n",
    "\n",
    "# Compute metrics using the functions defined earlier\n",
    "ious = compute_iou(all_preds, all_labels, num_classes=3)\n",
    "dices = compute_dice(all_preds, all_labels, num_classes=3)\n",
    "conf_matrix = compute_confusion_matrix(all_preds, all_labels, num_classes=3)\n",
    "precisions, recalls, f1s = compute_precision_recall_f1(conf_matrix)\n",
    "\n",
    "print(\"IoU per class:\", ious)\n",
    "print(\"Dice per class:\", dices)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Precision per class:\", precisions)\n",
    "print(\"Recall per class:\", recalls)\n",
    "print(\"F1 per class:\", f1s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef44714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

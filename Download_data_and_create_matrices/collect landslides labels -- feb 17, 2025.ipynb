{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40963274",
   "metadata": {},
   "source": [
    "#### coordinates left=-124.00055555649317, bottom=41.9994444436071, right=-122.99944444340576, top=43.00055555579519"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab9b7bea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the final 3D matrix: (1096, 1, 122, 29641)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import box, mapping\n",
    "from datetime import datetime\n",
    "\n",
    "def read_raster_within_bounds(raster_path, min_lon, max_lon, min_lat, max_lat):\n",
    "    \"\"\"Read raster and extract matrix based on the bounding box.\"\"\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Create a bounding box using Shapely geometry\n",
    "        bbox = box(min_lon, min_lat, max_lon, max_lat)\n",
    "        geo_json = [mapping(bbox)]  # Convert to GeoJSON format\n",
    "        \n",
    "        # Apply mask (crop raster)\n",
    "        out_image, out_transform = mask(src, geo_json, crop=True)\n",
    "        \n",
    "        return out_image\n",
    "\n",
    "def process_raster_files(directory, min_lon, max_lon, min_lat, max_lat, start_date, end_date):\n",
    "    \"\"\"Process all raster files in the given directory within the date range.\"\"\"\n",
    "    all_matrices = []\n",
    "    \n",
    "    # Iterate over all the files in the given directory\n",
    "    for file_name in os.listdir(directory):\n",
    "        # Only process .tif files that match the pattern\n",
    "        if file_name.endswith('.tif') and file_name.startswith('Global_Landslide_Nowcast_v1.1'):\n",
    "            \n",
    "            # Extract the date part (yyyyMMdd) from the filename\n",
    "            try:\n",
    "                # Filename format: Global_Landslide_Nowcast_v1.1_yyyyMMdd.tif\n",
    "                date_str = file_name.split('_')[-1].split('.')[0]  # Extract yyyyMMdd\n",
    "                file_date = datetime.strptime(date_str, '%Y%m%d')  # Convert to datetime object\n",
    "                \n",
    "                # Check if the file date is within the specified date range\n",
    "                if start_date <= file_date <= end_date:\n",
    "                    #print(file_name)\n",
    "                    raster_path = os.path.join(directory, file_name)\n",
    "                    # Read the raster and get the matrix\n",
    "                    matrix = read_raster_within_bounds(raster_path, min_lon, max_lon, min_lat, max_lat)\n",
    "                    #matrix = matrix.reshape((1, 122, 29641))  # Reshape to desired shape if needed\n",
    "                    all_matrices.append(matrix)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_name}: {e}\")\n",
    "    \n",
    "    # Convert list to a numpy array (if you want to have it as a 3D numpy array)\n",
    "    all_matrices = np.array(all_matrices)\n",
    "\n",
    "    return all_matrices\n",
    "\n",
    "# Define the bounds (latitudes and longitudes)\n",
    "# Define the bounds (latitudes and longitudes)\n",
    "min_lon = 124.00055555649317\n",
    "max_lon = -122.99944444340576\n",
    "min_lat = 41.9994444436071\n",
    "max_lat = 43.00055555579519\n",
    "\n",
    "# Date range for filtering the files\n",
    "start_date = datetime(2018, 1, 1)\n",
    "end_date = datetime(2020, 12, 31)\n",
    "\n",
    "# Directory containing your raster files\n",
    "raster_directory = 'GlobalLandslidesfrom2015to2020'\n",
    "\n",
    "# Process the files and get the appended matrices\n",
    "all_raster_matrices = process_raster_files(raster_directory, min_lon, max_lon, min_lat, max_lat, start_date, end_date)\n",
    "\n",
    "# Output the shape of the final 3D numpy array\n",
    "print(f\"Shape of the final 3D matrix: {all_raster_matrices.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "159b5963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the modified matrix: (1096, 120, 29640)\n",
      "Value: 0, Count: 3651416987\n",
      "Value: 1, Count: 21298098\n",
      "Value: 2, Count: 6744115\n",
      "Value: 255, Count: 218793600\n"
     ]
    }
   ],
   "source": [
    "squeezed_matrix = np.squeeze(all_raster_matrices)\n",
    "modified_matrix = squeezed_matrix[:, 1:-1, :-1]\n",
    "print(f\"Shape of the modified matrix: {modified_matrix.shape}\")\n",
    "unique_values, counts = np.unique(modified_matrix, return_counts=True)\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"Value: {value}, Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67a49ef1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "Shape of the imputed matrix: (1096, 120, 29640)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Reshape the matrix to a 2D array for KNN imputation (Each 2D slice is processed separately)\n",
    "num_slices = modified_matrix.shape[0]\n",
    "num_rows = modified_matrix.shape[1]\n",
    "num_columns = modified_matrix.shape[2]\n",
    "\n",
    "# KNN Imputer setup with k=3 for less resource consumption\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "# Create an empty matrix to store the imputed values\n",
    "imputed_matrix = np.empty_like(modified_matrix, dtype=np.float32)\n",
    "\n",
    "for i in range(num_slices):\n",
    "    if i%50 == 0:\n",
    "        print(i)\n",
    "    # Extract the 2D slice\n",
    "    slice_data = modified_matrix[i]\n",
    "\n",
    "    # Create a mask for missing values (255 signifies missing)\n",
    "    mask = slice_data == 255\n",
    "\n",
    "    # Replace 255 with NaN for imputation\n",
    "    slice_data_with_nan = np.where(mask, np.nan, slice_data)\n",
    "\n",
    "    # Fix columns that are entirely NaN by replacing them with a default value (e.g., mean of non-NaN values)\n",
    "    # Check for columns that are entirely NaN and replace them with a fixed value (e.g., 0 or mean of other columns)\n",
    "    for col in range(slice_data_with_nan.shape[1]):\n",
    "        if np.all(np.isnan(slice_data_with_nan[:, col])):\n",
    "            # You can replace the column with a default value like 0 or mean of other columns\n",
    "            slice_data_with_nan[:, col] = 0  # Or replace with np.nanmean(slice_data_with_nan[:, ~mask.any(axis=0)], axis=0)\n",
    "    \n",
    "    # Perform KNN imputation on this 2D slice\n",
    "    slice_imputed = imputer.fit_transform(slice_data_with_nan)\n",
    "\n",
    "    # Store the imputed slice back into the result matrix\n",
    "    imputed_matrix[i] = slice_imputed\n",
    "\n",
    "# Now, imputed_matrix contains the imputed data\n",
    "print(f\"Shape of the imputed matrix: {imputed_matrix.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "407812a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value: 0.0, Count: 3870210587\n",
      "Value: 1.0, Count: 21298098\n",
      "Value: 2.0, Count: 6744115\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(imputed_matrix, return_counts=True)\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"Value: {value}, Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37a5368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save multiple matrices (or just one matrix) to a compressed .npz file\n",
    "np.savez_compressed('landslide_labels_stored_sequentially_compressed.npz', matrix=imputed_matrix)\n",
    "\n",
    "# # To load it later:\n",
    "# loaded_data = np.load('matrix_compressed.npz')\n",
    "# loaded_matrix = loaded_data['matrix']\n",
    "# print(loaded_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb40f75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1096, 120, 29640)\n"
     ]
    }
   ],
   "source": [
    "# To load it later: checking\n",
    "loaded_data = np.load('landslide_labels_stored_sequentially_compressed.npz')\n",
    "loaded_matrix = loaded_data['matrix']\n",
    "print(loaded_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45c95bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
